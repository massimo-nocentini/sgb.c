\input cwebmac
% This file is part of the Stanford GraphBase (c) Stanford University 1993
% This material goes at the beginning of all Stanford GraphBase CWEB files

\def\topofcontents{
  \leftline{\sc\today\ at \hours}\bigskip\bigskip
  \centerline{\titlefont\title}}

\font\ninett=cmtt9
\def\botofcontents{\vskip 0pt plus 1filll
    \ninerm\baselineskip10pt
    \noindent\copyright\ 1993 Stanford University
    \bigskip\noindent
    This file may be freely copied and distributed, provided that
    no changes whatsoever are made. All users are asked to help keep
    the Stanford GraphBase files consistent and ``uncorrupted,''
    identical everywhere in the world. Changes are permissible only
    if the modified file is given a new name, different from the names of
    existing files in the Stanford GraphBase, and only if the modified file is
    clearly identified as not being part of that GraphBase.
    (The {\ninett CWEB} system has a ``change file'' facility by
    which users can easily make minor alterations without modifying
    the master source files in any way. Everybody is supposed to use
    change files instead of changing the files.)
    The author has tried his best to produce correct and useful programs,
    in order to help promote computer science research,
    but no warranty of any kind should be assumed.
    \smallskip\noindent
    Preliminary work on the Stanford GraphBase project
    was supported in part by National Science
    Foundation grant CCR-86-10181.}

\def\prerequisite#1{\def\startsection{\noindent
    Important: Before reading {\sc\title},
    please read or at least skim the program for {\sc#1}.\bigskip
    \let\startsection=\stsec\stsec}}
\def\prerequisites#1#2{\def\startsection{\noindent
    Important: Before reading {\sc\title}, please read
    or at least skim the programs for {\sc#1} and {\sc#2}.\bigskip
    \let\startsection=\stsec\stsec}}



\def\title{GB\_WORDS}
\font\logosl=logosl10

\prerequisites{GB\_\,GRAPH}{GB\_\,IO}

\N{1}{1}Introduction. This GraphBase module provides two external subroutines:
$$\vcenter{\halign{#\hfil\cr
\PB{\\{words}}, a routine that creates a graph based on five-letter words;\cr
\PB{\\{find\_word}}, a routine that looks for a given vertex in such a graph.%
\cr}}$$
Examples of the use of these routines can be found in two demo programs,
{\sc WORD\_\,COMPONENTS} and {\sc LADDERS}.

\Y\B\4\X1:\.{gb\_words.h\,}\X${}\E{}$\6
\&{extern} \&{Graph} ${}{*}\\{words}(\,);{}$\6
\&{extern} \&{Vertex} ${}{*}\\{find\_word}(\,){}$;\par
\A26.\fi

\M{2}The subroutine call \PB{$\\{words}(\|n,\\{wt\_vector},\\{wt\_threshold},%
\\{seed})$}
constructs a graph based on the five-letter words in \.{words.dat}.
Each vertex of the graph corresponds to a single five-letter word. Two
words are adjacent in the graph if they are the same except in one
letter position. For example, `\.{words}' is adjacent to other words such as
`\.{cords}', `\.{wards}', `\.{woods}', `\.{worms}', and `\.{wordy}'.

The constructed graph has at most \PB{\|n} vertices; indeed, it has exactly
\PB{\|n} vertices if there are enough qualifying words. A word qualifies
if its ``weight'' is \PB{\\{wt\_threshold}} or more, when weights are
computed from a table pointed to by~\PB{\\{wt\_vector}} according to rules
described below. (If parameter~\PB{\\{wt\_vector}}
is \PB{$\NULL$}, i.e., \.{NULL}, default weights are used.) The fourth
parameter,
\PB{\\{seed}}, is the seed of a random number generator.

All words of \.{words.dat} will be sorted by weight. The first vertex of
the graph will be the word of largest
weight, the second vertex will have second-largest weight, and so on.
Words of equal weight will appear in pseudo-random order, as determined
by the value of \PB{\\{seed}} in a system-independent fashion.
The first \PB{\|n} words in order of decreasing weight are chosen to be
vertices of the graph. However, if fewer than \PB{\|n} words have weight \PB{$%
\G$ \\{wt\_threshold}}, the graph will contain only the words that qualify. In
such cases the graph will have fewer than \PB{\|n} vertices---possibly none at
all.

Exception: The special case \PB{$\|n\K\T{0}$} is equivalent to the case when %
\PB{\|n}
has been set to the highest possible value. It causes all qualifying
words to appear.

\fi

\M{3}Every word in \.{words.dat} has been classified as `common' (\.*),
`advanced'
(\.+), or `unusual' (\.\ ). Each word has also been assigned seven
frequency counts $c_1$, \dots,~$c_7$, separated by commas; these counts show
how often the word has occurred in different publication contexts:
$$\vcenter{\halign{$c_#$ times in &#\hfil\cr
1&the American Heritage Intermediate Corpus of elementary school material;\cr
2&the Brown Corpus of reading material from America;\cr
3&the Lancaster-Oslo/Bergen Corpus of reading material from Britain;\cr
4&the Melbourne-Surrey Corpus of newspaper material from Australia;\cr
5&the Revised Standard Version of the Bible;\cr
6&{\sl The \TEX/book\/} and {\sl The {\logosl METAFONT\kern1pt}book\/}
by D. E. Knuth;\cr
7&{\sl Concrete Mathematics\/} by Graham, Knuth, and Patashnik.\cr}}$$
For example, one of the entries in \.{words.dat} is
$$\.{happy*774,92,121,2,26,8,1}$$
indicating a common word with $c_1=774$, \dots, $c_7=1$.

Parameter \PB{\\{wt\_vector}} points to an array of nine integers
$(a,b,w_1,\ldots,w_7)$.
The weight of each word is computed from these nine numbers by using the
formula
$$c_1w_1+\cdots+c_7w_7+
\cases{a,&if the word is `common';\cr
b,&if the word is `advanced';\cr
0,&if the word is `unusual'.\cr}$$
The components of \PB{\\{wt\_vector}} must be chosen so that
$$\max\bigl(\vert a\vert, \vert b\vert\bigr)
+ C_1\vert w_1\vert + \cdots +C_7\vert w_7\vert < 2^{30},$$
where $C_j$ is the maximum value of $c_j$ in the file; this restriction
ensures that the \PB{\\{words}} procedure will produce the same results on all
computer systems.

\fi

\M{4}The maximum frequency counts actually present are $C_1=15194$, $C_2=3560$,
$C_3=4467$, $C_4=460$, $C_5=6976$, $C_6=756$, and $C_7=362$; these can be
found in the entries for the common words `\.{shall}', `\.{there}',
`\.{which}', and `\.{would}'.

The default weights are $a=100$, $b=10$, $c_1=4$, $c_2=c_3=2$, $c_4=c_5=
c_6=c_7=1$.

File \.{words.dat} contains 5757 words, of which 3300 are `common', 1194 are
`advanced', and 1263 are `unusual'. Included among the unusual words are
891 having $c_1=\cdots=c_7=0$; such words
will always have weight zero, regardless of the weight vector parameter.

\Y\B\4\X4:Private variables\X${}\E{}$\6
\&{static} \&{long} \\{max\_c}[\,]${}\K\{\T{15194},\39\T{3560},\39\T{4467},\39%
\T{460},\39\T{6976},\39\T{756},\39\T{362}\}{}$;\C{ maximum counts $C_j$ }\6
\&{static} \&{long} \\{default\_wt\_vector}[\,]${}\K\{\T{100},\39\T{10},\39%
\T{4},\39\T{2},\39\T{2},\39\T{1},\39\T{1},\39\T{1},\39\T{1}\}{}$;\C{ use this
if \PB{$\\{wt\_vector}\K\NULL$} }\par
\As17\ET25.
\U7.\fi

\M{5}Examples: If you call \PB{$\\{words}(\T{2000},\NULL,\T{0},\T{0})$}, you
get a graph with
2000 of the most common five-letter words of English, using the
default weights.  The GraphBase programs are designed to be
system-independent, so that identical graphs will be obtained by
everybody who asks for \PB{$\\{words}(\T{2000},\NULL,\T{0},\T{0})$}.
Equivalent experiments
on algorithms for graph manipulation can therefore be performed by
researchers in different parts of the world.

The subroutine call \PB{$\\{words}(\T{2000},\NULL,\T{0},\|s)$} will produce
slightly
different graphs when the random seed \PB{\|s} varies, because some words
have equal weight. However, the graph for any particular value of~\PB{\|s}
will be the same on all computers. The seed value can be any integer
in the range $0\le s<2^{31}$.

Suppose you call \PB{$\\{words}(\T{0},\|w,\T{1},\T{0})$}, with \PB{\|w} defined
by the \CEE/ declaration
$$\hbox{\PB{\&{long} \|w[\T{9}]${}\K\{\T{1}\};$}}$$
this means that $a=1$ and $b=w_1=\cdots=w_7=0$. Therefore you'll get a graph
containing only the 3300 `common' words. Similarly, it's possible to obtain
only the $3300+1194=4494$ non-`unusual' words, by specifying the weight vector
$$\hbox{\PB{\&{long} \|w[\T{9}]${}\K\{\T{1},\T{1}\};$}}$$
this makes $a=b=1$ and $w_1=\cdots=w_7=0$. In both of these examples, the
qualifying words all have weight~1, so the vertices of the graph will appear
in pseudo-random order.

If \PB{\|w} points to an array of nine 0's, the call \PB{$\\{words}(\|n,\|w,%
\T{0},\|s)$} gives a
random sample of \PB{\|n} words, depending on \PB{\|s} in a system-independent
fashion.

If the entries of the weight vector are all nonnegative, and if the
weight threshold is zero, every word of \.{words.dat} will qualify. Thus
you will obtain a graph with $\min(n,5757)$ vertices.

If \PB{\|w} points to an array with {\sl negative\/} weights, the call
\PB{$\\{words}(\|n,\|w,{-}\T{\^7fffffff},\T{0})$} selects \PB{\|n} of the {\sl
least\/} common
words in \.{words.dat}.

\fi

\M{6}If the \PB{\\{words}} routine encounters a problem, it returns \PB{$%
\NULL$}, after putting
a code number into the external variable \PB{\\{panic\_code}}. This code number
identifies the type of failure. Otherwise \PB{\\{words}} returns a pointer to
the
newly created graph, which will be represented with the data structures
explained in {\sc GB\_\,GRAPH}. (The external variable \PB{\\{panic\_code}} is
itself
defined in {\sc GB\_\,GRAPH}.)

\Y\B\4\D$\\{panic}(\|c)$ \5
${}\{{}$\5
\1\\{gb\_free}(\\{node\_blocks});\6
${}\\{panic\_code}\K\|c{}$;\5
${}\\{gb\_trouble\_code}\K\T{0}{}$;\5
\&{return} ${}\NULL{}$;\5
${}\}{}$\2\par
\fi

\M{7}Now let's get going on the program. The \CEE/ file \.{gb\_words.c} begins
as follows:

\Y\B\8\#\&{include} \.{"gb\_io.h"}\C{ we will use the {\sc GB\_\,IO} routines
for input }\6
\8\#\&{include} \.{"gb\_flip.h"}\C{ we will use the {\sc GB\_\,FLIP} routines
for random numbers }\6
\8\#\&{include} \.{"gb\_graph.h"}\C{ we will use the {\sc GB\_\,GRAPH} data
structures }\6
\8\#\&{include} \.{"gb\_sort.h"}\C{ and \PB{\\{gb\_linksort}} for sorting }\6
\ATH\7
\X15:Type declarations\X\6
\X4:Private variables\X\6
\X10:Private functions\X\7
\1\1\&{Graph} ${}{*}\\{words}(\|n,\39\\{wt\_vector},\39\\{wt\_threshold},\39%
\\{seed}){}$\6
\&{unsigned} \&{long} \|n;\C{ maximum number of vertices desired }\6
\&{long} \\{wt\_vector}[\,];\C{ pointer to array of weights }\6
\&{long} \\{wt\_threshold};\C{ minimum qualifying weight }\6
\&{long} \\{seed};\C{ random number seed }\2\2\6
${}\{{}$\5
\1\X8:Local variables\X\7
\\{gb\_init\_rand}(\\{seed});\6
\X9:Check that \PB{\\{wt\_vector}} is valid\X;\6
\X18:Input the qualifying words to a linked list, computing their weights\X;\6
\X22:Sort and output the words, determining adjacencies\X;\6
\&{if} (\\{gb\_trouble\_code})\5
${}\{{}$\1\6
\\{gb\_recycle}(\\{new\_graph});\6
\\{panic}(\\{alloc\_fault});\C{ oops, we ran out of memory somewhere back there
}\6
\4${}\}{}$\2\6
\&{return} \\{new\_graph};\6
\4${}\}{}$\2\par
\fi

\M{8}\B\X8:Local variables\X${}\E{}$\6
\&{Graph} ${}{*}\\{new\_graph}{}$;\C{ the graph constructed by \PB{\\{words}} }%
\par
\As14, 16\ETs24.
\U7.\fi

\N{1}{9}Validating the weights. The first job that \PB{\\{words}} needs to
tackle is
comparatively trivial:
We want to verify the condition
$$\max\bigl(\vert a\vert, \vert b\vert\bigr)
+ C_1\vert w_1\vert + \cdots +C_7\vert w_7\vert < 2^{30}.\eqno(*)$$
This proves to be an interesting exercise in ``portable
\CEE/ programming,'' because we don't want to risk integer overflow.
Our approach is to do the
calculation first in floating point arithmetic, thereby ruling out cases
that are clearly unacceptable. Once that test is passed, we can safely
test the condition with ordinary integer arithmetic. Floating
point arithmetic is system dependent, but we use it carefully so that
system-independent results are obtained.

\Y\B\4\X9:Check that \PB{\\{wt\_vector}} is valid\X${}\E{}$\6
\&{if} ${}(\R\\{wt\_vector}){}$\1\5
${}\\{wt\_vector}\K\\{default\_wt\_vector};{}$\2\6
\&{else}\5
${}\{{}$\5
\1\&{register} \&{double} \\{flacc};\6
\&{register} \&{long} ${}{*}\|p,\39{*}\|q;{}$\6
\&{register} \&{long} \\{acc};\7
\X11:Use floating point arithmetic to check that \PB{\\{wt\_vector}} isn't
totally off base\X;\6
\X12:Use integer arithmetic to check that \PB{\\{wt\_vector}} is truly OK\X;\6
\4${}\}{}$\2\par
\U7.\fi

\M{10}The floating-point calculations are facilitated by a routine that
converts an integer to its absolute value, expressed as a \PB{\&{double}}:

\Y\B\4\X10:Private functions\X${}\E{}$\6
\1\1\&{static} \&{double} \\{flabs}(\|x)\6
\&{long} \|x;\2\2\6
${}\{{}$\5
\1\&{if} ${}(\|x\G\T{0}){}$\1\5
\&{return} (\&{double})\,\|x;\2\6
\&{return} ${}{-}((\&{double})\,\|x);{}$\6
\4${}\}{}$\2\par
\A13.
\U7.\fi

\M{11}Although floating point arithmetic is system dependent, we can certainly
assume that at least 16 bits of precision are used. This implies that
the difference between \PB{\\{flabs}(\|x)} and $\vert x\vert$ must be less
than $2^{14}$. Also, if $x$ and $y$ are nonnegative values less than $2^{31}$,
the difference between their floating-point sum and their true sum must be
less than $2^{14}$.

The floating point calculations in the following test will never reject a
valid weight vector. For if condition $(*)$ holds, the floating-point value of
$\max(\hbox{\PB{\\{flabs}(\|a)}},\hbox{\PB{\\{flabs}(\|b)}})+C_1*\PB{%
\\{flabs}}(w_1)+\cdots
+C_7*\PB{\\{flabs}}(w_7)$ will be less than $2^{30}+(8+C_1+\cdots+C_7)2^{14}$,
which is less than $2^{30}+2^{29}$.

\Y\B\4\X11:Use floating point arithmetic to check that \PB{\\{wt\_vector}}
isn't totally off base\X${}\E{}$\6
$\|p\K\\{wt\_vector};{}$\6
${}\\{flacc}\K\\{flabs}({*}\|p\PP);{}$\6
\&{if} ${}(\\{flacc}<\\{flabs}({*}\|p)){}$\1\5
${}\\{flacc}\K\\{flabs}({*}\|p){}$;\C{ now $\PB{\\{flacc}}=\max(\vert a\vert,%
\vert b\vert)$ }\2\6
\&{for} ${}(\|q\K{\AND}\\{max\_c}[\T{0}];{}$ ${}\|q<{\AND}\\{max\_c}[\T{7}];{}$
${}\|q\PP){}$\1\5
${}\\{flacc}\MRL{+{\K}}{*}\|q*\\{flabs}({*}\PP\|p);{}$\2\6
\&{if} ${}(\\{flacc}\G(\&{double})\,\T{\^60000000}{}$)\C{ this constant is
$6\times2^{28}=2^{30}+2^{29}$ }\1\6
\\{panic}(\\{very\_bad\_specs});\C{ whoa; the weight vector is way too big }\2%
\par
\U9.\fi

\M{12}Conversely, if the floating point test just made is passed, the true
value of the sum will be less than $2^{30}+2^{29}+2^{29}=2^{31}$; hence
integer overflow will never occur when we make the following more
refined test:

\Y\B\4\X12:Use integer arithmetic to check that \PB{\\{wt\_vector}} is truly OK%
\X${}\E{}$\6
$\|p\K\\{wt\_vector};{}$\6
${}\\{acc}\K\\{iabs}({*}\|p\PP);{}$\6
\&{if} ${}(\\{acc}<\\{iabs}({*}\|p)){}$\1\5
${}\\{acc}\K\\{iabs}({*}\|p){}$;\C{ now $\PB{\\{acc}}=\max(\vert a\vert,\vert b%
\vert)$ }\2\6
\&{for} ${}(\|q\K{\AND}\\{max\_c}[\T{0}];{}$ ${}\|q<{\AND}\\{max\_c}[\T{7}];{}$
${}\|q\PP){}$\1\5
${}\\{acc}\MRL{+{\K}}{*}\|q*\\{iabs}({*}\PP\|p);{}$\2\6
\&{if} ${}(\\{acc}\G\T{\^40000000}){}$\1\5
\\{panic}(\\{bad\_specs});\C{ the weight vector is a bit too big }\2\par
\U9.\fi

\M{13}\B\X10:Private functions\X${}\mathrel+\E{}$\6
\1\1\&{static} \&{long} \\{iabs}(\|x)\6
\&{long} \|x;\2\2\6
${}\{{}$\5
\1\&{if} ${}(\|x\G\T{0}){}$\1\5
\&{return} (\&{long})\,\|x;\2\6
\&{return} ${}{-}((\&{long})\,\|x);{}$\6
\4${}\}{}$\2\par
\fi

\N{1}{14}The input phase. Now we're ready to read \.{words.dat}.

\Y\B\4\X8:Local variables\X${}\mathrel+\E{}$\6
\&{register} \&{long} \\{wt};\C{ the weight of the current word }\6
\&{char} \\{word}[\T{5}];\C{ the current five-letter word }\6
\&{long} \\{nn}${}\K\T{0}{}$;\C{ the number of qualifying words found so far }%
\par
\fi

\M{15}As we read the words, we will form a linked list of nodes containing
each qualifying word and its weight, using the memory management
routines of {\sc GB\_\,GRAPH} to allocate space for 111 nodes at a
time. These nodes should be returned to available memory later, so we
will keep them in a separate area under local control.

The nodes start out with \PB{\\{key}} and \PB{\\{link}} fields, as required by
the
\PB{\\{gb\_linksort}} routine, which we'll use to sort by weight. The sort key
must be
nonnegative; we obtain it by adding $2^{30}$ to the weight.

\Y\B\4\D$\\{nodes\_per\_block}$ \5
\T{111}\par
\Y\B\4\X15:Type declarations\X${}\E{}$\6
\&{typedef} \&{struct} \&{node\_struct} ${}\{{}$\1\6
\&{long} \\{key};\C{ the sort key (weight plus $2^{30}$) }\6
\&{struct} \&{node\_struct} ${}{*}\\{link}{}$;\C{ links the nodes together }\6
\&{char} \\{wd}[\T{5}];\C{ five-letter word                    (which typically
consumes eight bytes, too bad) }\2\6
${}\}{}$ \&{node};\par
\A23.
\U7.\fi

\M{16}\B\X8:Local variables\X${}\mathrel+\E{}$\6
\&{node} ${}{*}\\{next\_node}{}$;\C{ the next node available for allocation }\6
\&{node} ${}{*}\\{bad\_node}{}$;\C{ if \PB{$\\{next\_node}\K\\{bad\_node}$},
the node isn't really there }\6
\&{node} ${}{*}\\{stack\_ptr}{}$;\C{ the most recently created node }\6
\&{node} ${}{*}\\{cur\_node}{}$;\C{ current node being created or examined }\par
\fi

\M{17}\B\X4:Private variables\X${}\mathrel+\E{}$\6
\&{static} \&{Area} \\{node\_blocks};\C{ the memory area for blocks of nodes }%
\par
\fi

\M{18}\B\X18:Input the qualifying words to a linked list, computing their
weights\X${}\E{}$\6
$\\{next\_node}\K\\{bad\_node}\K\\{stack\_ptr}\K\NULL;{}$\6
\&{if} ${}(\\{gb\_open}(\.{"words.dat"})\I\T{0}){}$\1\5
\\{panic}(\\{early\_data\_fault});\C{ couldn't open \PB{\.{"words.dat"}} using
GraphBase conventions;                 \PB{\\{io\_errors}} tells why }\2\6
\&{do}\5
\X19:Read one word, and put it on the stack if it qualifies\X\5
\&{while} ${}(\R\\{gb\_eof}(\,));{}$\6
\&{if} ${}(\\{gb\_close}(\,)\I\T{0}){}$\1\5
\\{panic}(\\{late\_data\_fault});\C{ something's wrong with \PB{%
\.{"words.dat"}}; see \PB{\\{io\_errors}} }\2\par
\U7.\fi

\M{19}\B\X19:Read one word, and put it on the stack if it qualifies\X${}\E{}$\6
${}\{{}$\5
\1\&{register} \&{long} \|j;\C{ position in \PB{\\{word}} }\7
\&{for} ${}(\|j\K\T{0};{}$ ${}\|j<\T{5};{}$ ${}\|j\PP){}$\1\5
${}\\{word}[\|j]\K\\{gb\_char}(\,);{}$\2\6
\X21:Compute the weight \PB{\\{wt}}\X;\6
\&{if} ${}(\\{wt}\G\\{wt\_threshold}){}$\5
${}\{{}$\C{ it qualifies }\1\6
\X20:Install \PB{\\{word}} and \PB{\\{wt}} in a new node\X;\6
${}\\{nn}\PP;{}$\6
\4${}\}{}$\2\6
\\{gb\_newline}(\,);\6
\4${}\}{}$\2\par
\U18.\fi

\M{20}\B\D$\\{copy5}(\|y,\|x)$ \6
${}\{{}$\5
\1${}{*}(\|y)\K{*}(\|x){}$;\5
${}{*}((\|y)+\T{1})\K{*}((\|x)+\T{1}){}$;\5
${}{*}((\|y)+\T{2})\K{*}((\|x)+\T{2});{}$\6
${}{*}((\|y)+\T{3})\K{*}((\|x)+\T{3}){}$;\5
${}{*}((\|y)+\T{4})\K{*}((\|x)+\T{4}){}$;\5
${}\}{}$\2\par
\Y\B\4\X20:Install \PB{\\{word}} and \PB{\\{wt}} in a new node\X${}\E{}$\6
\&{if} ${}(\\{next\_node}\E\\{bad\_node}){}$\5
${}\{{}$\1\6
${}\\{cur\_node}\K\\{gb\_typed\_alloc}(\\{nodes\_per\_block},\39\&{node},\39%
\\{node\_blocks});{}$\6
\&{if} ${}(\\{cur\_node}\E\NULL){}$\1\5
${}\\{panic}(\\{no\_room}+\T{1}){}$;\C{ out of memory already }\2\6
${}\\{next\_node}\K\\{cur\_node}+\T{1};{}$\6
${}\\{bad\_node}\K\\{cur\_node}+\\{nodes\_per\_block};{}$\6
\4${}\}{}$\5
\2\&{else}\1\5
${}\\{cur\_node}\K\\{next\_node}\PP;{}$\2\6
${}\\{cur\_node}\MG\\{key}\K\\{wt}+\T{\^40000000};{}$\6
${}\\{cur\_node}\MG\\{link}\K\\{stack\_ptr};{}$\6
${}\\{copy5}(\\{cur\_node}\MG\\{wd},\39\\{word});{}$\6
${}\\{stack\_ptr}\K\\{cur\_node}{}$;\par
\U19.\fi

\M{21}Recall that \PB{\\{gb\_number}(\,)} returns 0, without giving an error,
if no
digit is present in the current position of the file being read. This
implies that the \.{words.dat} file need not include zero counts
explicitly. Furthermore, we can arrange things so that trailing zero
counts are unnecessary; commas can be omitted if all counts
following them on the current line are zero.

\Y\B\4\X21:Compute the weight \PB{\\{wt}}\X${}\E{}$\6
${}\{{}$\5
\1\&{register} \&{long} ${}{*}\|p,\39{*}\|q{}$;\C{ pointers to $C_j$ and $w_j$
}\6
\&{register} \&{long} \|c;\C{ current count }\7
\&{switch} (\\{gb\_char}(\,))\5
${}\{{}$\1\6
\4\&{case} \.{'*'}:\5
${}\\{wt}\K\\{wt\_vector}[\T{0}]{}$;\5
\&{break};\C{ `common' word }\6
\4\&{case} \.{'+'}:\5
${}\\{wt}\K\\{wt\_vector}[\T{1}]{}$;\5
\&{break};\C{ `advanced' word }\6
\4\&{case} \.{'\ '}:\5
\&{case} \.{'\\n'}:\5
${}\\{wt}\K\T{0}{}$;\5
\&{break};\C{ `unusual' word }\6
\4\&{default}:\5
\\{panic}(\\{syntax\_error});\C{ unknown type of word }\6
\4${}\}{}$\2\6
${}\|p\K{\AND}\\{max\_c}[\T{0}];{}$\6
${}\|q\K{\AND}\\{wt\_vector}[\T{2}];{}$\6
\&{do}\5
${}\{{}$\1\6
\&{if} ${}(\|p\E{\AND}\\{max\_c}[\T{7}]){}$\1\5
${}\\{panic}(\\{syntax\_error}+\T{1}){}$;\C{ too many counts }\2\6
${}\|c\K\\{gb\_number}(\T{10});{}$\6
\&{if} ${}(\|c>{*}\|p\PP){}$\1\5
${}\\{panic}(\\{syntax\_error}+\T{2}){}$;\C{ count too large }\2\6
${}\\{wt}\MRL{+{\K}}\|c*{*}\|q\PP;{}$\6
\4${}\}{}$\5
\2\5
\&{while} ${}(\\{gb\_char}(\,)\E\.{','});{}$\6
\4${}\}{}$\2\par
\U19.\fi

\N{1}{22}The output phase. Once the input phase has examined all of
\.{words.dat}, we are left with a stack of \PB{\\{nn}} nodes containing the
qualifying words, starting at \PB{\\{stack\_ptr}}.

The next step is to call \PB{\\{gb\_linksort}}, which takes the qualifying
words
and distributes them into the 128 lists \PB{\\{gb\_sorted}[\|j]}, for \PB{$%
\T{0}\Z\|j<\T{128}$}.
We can then access the words in order of decreasing weight by reading through
these lists, starting with \PB{\\{gb\_sorted}[\T{127}]} and ending with \PB{%
\\{gb\_sorted}[\T{0}]}.
(See the documentation of \PB{\\{gb\_linksort}} in the {\sc GB\_\,SORT}
module.)

The output phase therefore has the following general outline:

\Y\B\4\X22:Sort and output the words, determining adjacencies\X${}\E{}$\6
\\{gb\_linksort}(\\{stack\_ptr});\6
\X27:Allocate storage for the new graph; adjust \PB{\|n} if it is zero or too
large\X;\6
\&{if} ${}(\\{gb\_trouble\_code}\E\T{0}\W\|n){}$\5
${}\{{}$\1\6
\&{register} \&{long} \|j;\C{ runs through sorted lists }\6
\&{register} \&{node} ${}{*}\|p{}$;\C{ the current node being output }\7
${}\\{nn}\K\|n;{}$\6
\&{for} ${}(\|j\K\T{127};{}$ ${}\|j\G\T{0};{}$ ${}\|j\MM){}$\1\6
\&{for} ${}(\|p\K{}$(\&{node} ${}{*})\,\\{gb\_sorted}[\|j];{}$ \|p; ${}\|p\K\|p%
\MG\\{link}){}$\5
${}\{{}$\1\6
\X28:Add the word \PB{$\|p\MG\\{wd}$} to the graph\X;\6
\&{if} ${}(\MM\\{nn}\E\T{0}){}$\1\5
\&{goto} \\{done};\2\6
\4${}\}{}$\2\2\6
\4${}\}{}$\2\6
\4\\{done}:\5
\\{gb\_free}(\\{node\_blocks});\par
\U7.\fi

\M{23}The only slightly unusual data structure needed is a set of five hash
tables,
one for each of the strings of four letters obtained by suppressing
a single letter of a five-letter word. For example, a word like `\.{words}'
will lead to entries for `\.{\ ords}', `\.{w\ rds}', `\.{wo\ ds}', `\.{wor\
s}',
and `\.{word\ }', one in each of the hash tables.

\Y\B\4\D$\\{hash\_prime}$ \5
\T{6997}\C{ a prime number larger than the total number of words }\par
\Y\B\4\X15:Type declarations\X${}\mathrel+\E{}$\6
\&{typedef} \&{Vertex} ${}{*}\&{hash\_table}[\\{hash\_prime}]{}$;\par
\fi

\M{24}\B\X8:Local variables\X${}\mathrel+\E{}$\6
\&{Vertex} ${}{*}\\{cur\_vertex}{}$;\C{ the current vertex being created or
examined }\6
\&{char} ${}{*}\\{next\_string}{}$;\C{ where we'll store the next five-letter
word }\par
\fi

\M{25}\B\X4:Private variables\X${}\mathrel+\E{}$\6
\&{static} \&{hash\_table} ${}{*}\\{htab}{}$;\C{ five dynamically allocated
hash tables }\par
\fi

\M{26}The weight of each word will be stored in the utility field \PB{$\|u.%
\|I$} of its
\PB{\&{Vertex}} record. The position in which adjacent words differ will be
stored in utility field \PB{$\|a.\|I$} of the \PB{\&{Arc}} records between
them.

\Y\B\4\D$\\{weight}$ \5
$\|u.{}$\|I\C{ weighted frequencies }\par
\B\4\D$\\{loc}$ \5
$\|a.{}$\|I\C{ index of difference (0, 1, 2, 3, or 4) }\par
\Y\B\4\X1:\.{gb\_words.h\,}\X${}\mathrel+\E{}$\6
\8\#\&{define} \\{weight}\5${}\|u.\|I{}$\C{ repeat the definitions in the
header file }\6
\8\#\&{define} \\{loc}\5${}\|a.\|I{}$\par
\fi

\M{27}\B\X27:Allocate storage for the new graph; adjust \PB{\|n} if it is zero
or too large\X${}\E{}$\6
\&{if} ${}(\|n\E\T{0}\V\\{nn}<\|n){}$\1\5
${}\|n\K\\{nn};{}$\2\6
${}\\{new\_graph}\K\\{gb\_new\_graph}(\|n);{}$\6
\&{if} ${}(\\{new\_graph}\E\NULL){}$\1\5
\\{panic}(\\{no\_room});\C{ out of memory before we're even started }\2\6
\&{if} ${}(\\{wt\_vector}\E\\{default\_wt\_vector}){}$\1\5
${}\\{sprintf}(\\{new\_graph}\MG\\{id},\39\.{"words(\%lu,0,\%ld,\%ld}\)\.{)"},%
\39\|n,\39\\{wt\_threshold},\39\\{seed});{}$\2\6
\&{else}\1\5
${}\\{sprintf}(\\{new\_graph}\MG\\{id},\39\.{"words(\%lu,\{\%ld,\%ld,}\)\.{%
\%ld,\%ld,\%ld,\%ld,\%ld,}\)\.{\%ld,\%ld\},\%ld,\%ld)"},\39\|n,\39\\{wt%
\_vector}[\T{0}],\39\\{wt\_vector}[\T{1}],\39\\{wt\_vector}[\T{2}],\39\\{wt%
\_vector}[\T{3}],\39\\{wt\_vector}[\T{4}],\39\\{wt\_vector}[\T{5}],\39\\{wt%
\_vector}[\T{6}],\39\\{wt\_vector}[\T{7}],\39\\{wt\_vector}[\T{8}],\39\\{wt%
\_threshold},\39\\{seed});{}$\2\6
${}\\{strcpy}(\\{new\_graph}\MG\\{util\_types},\39\.{"IZZZZZIZZZZZZZ"});{}$\6
${}\\{cur\_vertex}\K\\{new\_graph}\MG\\{vertices};{}$\6
${}\\{next\_string}\K\\{gb\_typed\_alloc}(\T{6}*\|n,\39\&{char},\39\\{new%
\_graph}\MG\\{data});{}$\6
${}\\{htab}\K\\{gb\_typed\_alloc}(\T{5},\39\&{hash\_table},\39\\{new\_graph}\MG%
\\{aux\_data}){}$;\par
\U22.\fi

\M{28}\B\X28:Add the word \PB{$\|p\MG\\{wd}$} to the graph\X${}\E{}$\6
${}\{{}$\5
\1\&{register} \&{char} ${}{*}\|q{}$;\C{ the new word }\7
${}\|q\K\\{cur\_vertex}\MG\\{name}\K\\{next\_string};{}$\6
${}\\{next\_string}\MRL{+{\K}}\T{6};{}$\6
${}\\{copy5}(\|q,\39\|p\MG\\{wd});{}$\6
${}\\{cur\_vertex}\MG\\{weight}\K\|p\MG\\{key}-\T{\^40000000};{}$\6
\X29:Add edges for all previous words \PB{\|r} that nearly match \PB{\|q}\X;\6
${}\\{cur\_vertex}\PP;{}$\6
\4${}\}{}$\2\par
\U22.\fi

\M{29}The length of each edge in a \PB{\\{words}} graph is set to~1; the
calling routine can change it later if desired.

\Y\B\4\D$\\{mtch}(\|i)$ \5
$({*}(\|q+\|i)\E{*}(\|r+\|i){}$)\par
\B\4\D$\\{match}(\|a,\|b,\|c,\|d)$ \5
$(\\{mtch}(\|a)\W\\{mtch}(\|b)\W\\{mtch}(\|c)\W\\{mtch}(\|d){}$)\par
\B\4\D$\\{store\_loc\_of\_diff}(\|k)$ \5
$\\{cur\_vertex}\MG\\{arcs}\MG\\{loc}\K(\\{cur\_vertex}\MG\\{arcs}-\T{1})\MG%
\\{loc}\K{}$\|k\par
\B\4\D$\\{ch}(\|q)$ \5
$((\&{long})\,{*}(\|q){}$)\par
\B\4\D$\\{hdown}(\|k)$ \5
$\|h\E\\{htab}[\|k]\?\|h\K\\{htab}[\|k+\T{1}]-\T{1}:\|h\MM{}$\par
\Y\B\4\X29:Add edges for all previous words \PB{\|r} that nearly match \PB{\|q}%
\X${}\E{}$\6
${}\{{}$\5
\1\&{register} \&{char} ${}{*}\|r{}$;\C{ previous word possibly adjacent to %
\PB{\|q} }\6
\&{register} \&{Vertex} ${}{*}{*}\|h{}$;\C{ hash address for linear probing }\6
\&{register} \&{long} \\{raw\_hash};\C{ five-letter hash code before
remaindering }\7
${}\\{raw\_hash}\K(((((((\\{ch}(\|q)\LL\T{5})+\\{ch}(\|q+\T{1}))\LL\T{5})+%
\\{ch}(\|q+\T{2}))\LL\T{5})+\\{ch}(\|q+\T{3}))\LL\T{5})+\\{ch}(\|q+\T{4});{}$\6
\&{for} ${}(\|h\K\\{htab}[\T{0}]+(\\{raw\_hash}-(\\{ch}(\|q)\LL\T{20}))\MOD%
\\{hash\_prime};{}$ ${}{*}\|h;{}$ \\{hdown}(\T{0}))\5
${}\{{}$\1\6
${}\|r\K({*}\|h)\MG\\{name};{}$\6
\&{if} ${}(\\{match}(\T{1},\39\T{2},\39\T{3},\39\T{4})){}$\1\5
${}\\{gb\_new\_edge}(\\{cur\_vertex},\39{*}\|h,\39\T{1\$L}),\39\\{store\_loc%
\_of\_diff}(\T{0});{}$\2\6
\4${}\}{}$\2\6
${}{*}\|h\K\\{cur\_vertex};{}$\6
\&{for} ${}(\|h\K\\{htab}[\T{1}]+(\\{raw\_hash}-(\\{ch}(\|q+\T{1})\LL\T{15}))%
\MOD\\{hash\_prime};{}$ ${}{*}\|h;{}$ \\{hdown}(\T{1}))\5
${}\{{}$\1\6
${}\|r\K({*}\|h)\MG\\{name};{}$\6
\&{if} ${}(\\{match}(\T{0},\39\T{2},\39\T{3},\39\T{4})){}$\1\5
${}\\{gb\_new\_edge}(\\{cur\_vertex},\39{*}\|h,\39\T{1\$L}),\39\\{store\_loc%
\_of\_diff}(\T{1});{}$\2\6
\4${}\}{}$\2\6
${}{*}\|h\K\\{cur\_vertex};{}$\6
\&{for} ${}(\|h\K\\{htab}[\T{2}]+(\\{raw\_hash}-(\\{ch}(\|q+\T{2})\LL\T{10}))%
\MOD\\{hash\_prime};{}$ ${}{*}\|h;{}$ \\{hdown}(\T{2}))\5
${}\{{}$\1\6
${}\|r\K({*}\|h)\MG\\{name};{}$\6
\&{if} ${}(\\{match}(\T{0},\39\T{1},\39\T{3},\39\T{4})){}$\1\5
${}\\{gb\_new\_edge}(\\{cur\_vertex},\39{*}\|h,\39\T{1\$L}),\39\\{store\_loc%
\_of\_diff}(\T{2});{}$\2\6
\4${}\}{}$\2\6
${}{*}\|h\K\\{cur\_vertex};{}$\6
\&{for} ${}(\|h\K\\{htab}[\T{3}]+(\\{raw\_hash}-(\\{ch}(\|q+\T{3})\LL\T{5}))%
\MOD\\{hash\_prime};{}$ ${}{*}\|h;{}$ \\{hdown}(\T{3}))\5
${}\{{}$\1\6
${}\|r\K({*}\|h)\MG\\{name};{}$\6
\&{if} ${}(\\{match}(\T{0},\39\T{1},\39\T{2},\39\T{4})){}$\1\5
${}\\{gb\_new\_edge}(\\{cur\_vertex},\39{*}\|h,\39\T{1\$L}),\39\\{store\_loc%
\_of\_diff}(\T{3});{}$\2\6
\4${}\}{}$\2\6
${}{*}\|h\K\\{cur\_vertex};{}$\6
\&{for} ${}(\|h\K\\{htab}[\T{4}]+(\\{raw\_hash}-\\{ch}(\|q+\T{4}))\MOD\\{hash%
\_prime};{}$ ${}{*}\|h;{}$ \\{hdown}(\T{4}))\5
${}\{{}$\1\6
${}\|r\K({*}\|h)\MG\\{name};{}$\6
\&{if} ${}(\\{match}(\T{0},\39\T{1},\39\T{2},\39\T{3})){}$\1\5
${}\\{gb\_new\_edge}(\\{cur\_vertex},\39{*}\|h,\39\T{1\$L}),\39\\{store\_loc%
\_of\_diff}(\T{4});{}$\2\6
\4${}\}{}$\2\6
${}{*}\|h\K\\{cur\_vertex};{}$\6
\4${}\}{}$\2\par
\U28.\fi

\N{1}{30}Finding a word. After \PB{\\{words}} has created a graph \PB{\|g}, the
user can
remove the hash tables by calling \PB{$\\{gb\_free}(\|g\MG\\{aux\_data})$}. But
if the
hash tables have not been removed, another procedure can be used to
find vertices that match or nearly match a given word.

The subroutine call \PB{$\\{find\_word}(\|q,\|f)$} will return a pointer to a
vertex
that matches a given five-letter word~\PB{\|q}, if that word is in the graph;
otherwise, it returns \PB{$\NULL$} (i.e., \.{NULL}), after calling \PB{\|f(%
\|v)} for
each vertex~\PB{\|v} whose word matches \PB{\|q} in all but one letter
position.

\Y\B\1\1\&{Vertex} ${}{*}\\{find\_word}(\|q,\39\|f){}$\6
\&{char} ${}{*}\|q;{}$\6
\&{void} ${}({*}\|f)(\,){}$;\C{ \PB{${*}\|f$} should take one argument, of type
\PB{\&{Vertex} ${}{*}$},                         or \PB{\|f} should be \PB{$%
\NULL$} }\2\2\6
${}\{{}$\5
\1\&{register} \&{char} ${}{*}\|r{}$;\C{ previous word possibly adjacent to %
\PB{\|q} }\6
\&{register} \&{Vertex} ${}{*}{*}\|h{}$;\C{ hash address for linear probing }\6
\&{register} \&{long} \\{raw\_hash};\C{ five-letter hash code before
remaindering }\7
${}\\{raw\_hash}\K(((((((\\{ch}(\|q)\LL\T{5})+\\{ch}(\|q+\T{1}))\LL\T{5})+%
\\{ch}(\|q+\T{2}))\LL\T{5})+\\{ch}(\|q+\T{3}))\LL\T{5})+\\{ch}(\|q+\T{4});{}$\6
\&{for} ${}(\|h\K\\{htab}[\T{0}]+(\\{raw\_hash}-(\\{ch}(\|q)\LL\T{20}))\MOD%
\\{hash\_prime};{}$ ${}{*}\|h;{}$ \\{hdown}(\T{0}))\5
${}\{{}$\1\6
${}\|r\K({*}\|h)\MG\\{name};{}$\6
\&{if} ${}(\\{mtch}(\T{0})\W\\{match}(\T{1},\39\T{2},\39\T{3},\39\T{4})){}$\1\5
\&{return} ${}{*}\|h;{}$\2\6
\4${}\}{}$\2\6
\X31:Invoke \PB{\|f} on every vertex that is adjacent to word~\PB{\|q}\X;\6
\&{return} ${}\NULL;{}$\6
\4${}\}{}$\2\par
\fi

\M{31}\B\X31:Invoke \PB{\|f} on every vertex that is adjacent to word~\PB{\|q}%
\X${}\E{}$\6
\&{if} (\|f)\5
${}\{{}$\1\6
\&{for} ${}(\|h\K\\{htab}[\T{0}]+(\\{raw\_hash}-(\\{ch}(\|q)\LL\T{20}))\MOD%
\\{hash\_prime};{}$ ${}{*}\|h;{}$ \\{hdown}(\T{0}))\5
${}\{{}$\1\6
${}\|r\K({*}\|h)\MG\\{name};{}$\6
\&{if} ${}(\\{match}(\T{1},\39\T{2},\39\T{3},\39\T{4})){}$\1\5
${}({*}\|f)({*}\|h);{}$\2\6
\4${}\}{}$\2\6
\&{for} ${}(\|h\K\\{htab}[\T{1}]+(\\{raw\_hash}-(\\{ch}(\|q+\T{1})\LL\T{15}))%
\MOD\\{hash\_prime};{}$ ${}{*}\|h;{}$ \\{hdown}(\T{1}))\5
${}\{{}$\1\6
${}\|r\K({*}\|h)\MG\\{name};{}$\6
\&{if} ${}(\\{match}(\T{0},\39\T{2},\39\T{3},\39\T{4})){}$\1\5
${}({*}\|f)({*}\|h);{}$\2\6
\4${}\}{}$\2\6
\&{for} ${}(\|h\K\\{htab}[\T{2}]+(\\{raw\_hash}-(\\{ch}(\|q+\T{2})\LL\T{10}))%
\MOD\\{hash\_prime};{}$ ${}{*}\|h;{}$ \\{hdown}(\T{2}))\5
${}\{{}$\1\6
${}\|r\K({*}\|h)\MG\\{name};{}$\6
\&{if} ${}(\\{match}(\T{0},\39\T{1},\39\T{3},\39\T{4})){}$\1\5
${}({*}\|f)({*}\|h);{}$\2\6
\4${}\}{}$\2\6
\&{for} ${}(\|h\K\\{htab}[\T{3}]+(\\{raw\_hash}-(\\{ch}(\|q+\T{3})\LL\T{5}))%
\MOD\\{hash\_prime};{}$ ${}{*}\|h;{}$ \\{hdown}(\T{3}))\5
${}\{{}$\1\6
${}\|r\K({*}\|h)\MG\\{name};{}$\6
\&{if} ${}(\\{match}(\T{0},\39\T{1},\39\T{2},\39\T{4})){}$\1\5
${}({*}\|f)({*}\|h);{}$\2\6
\4${}\}{}$\2\6
\&{for} ${}(\|h\K\\{htab}[\T{4}]+(\\{raw\_hash}-\\{ch}(\|q+\T{4}))\MOD\\{hash%
\_prime};{}$ ${}{*}\|h;{}$ \\{hdown}(\T{4}))\5
${}\{{}$\1\6
${}\|r\K({*}\|h)\MG\\{name};{}$\6
\&{if} ${}(\\{match}(\T{0},\39\T{1},\39\T{2},\39\T{3})){}$\1\5
${}({*}\|f)({*}\|h);{}$\2\6
\4${}\}{}$\2\6
\4${}\}{}$\2\par
\U30.\fi

\N{1}{32}Index. Here is a list that shows where the identifiers of this program
are
defined and used.
\fi

\inx
\fin
\con
